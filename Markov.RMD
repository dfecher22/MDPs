
```{r}
library(MDPtoolbox)
library(matlab)

#first small MDP

P <- array(0, c(6,6,2))
P[,,1] <- matrix(c(
                   0,1,0,0,0,0,
                   0,1,0,0,0,0, #terminal state "transitions to self"
                   0,0,0,1,0,0,
                   0,0,0,1,0,0,
                   0,0,0,0,0,1,
                   0,0,0,0,0,1
                   
                   ), 6, 6, byrow=TRUE)
P[,,2] <- matrix(c(
                    0,0,1,0,0,0,
                    0,1,0,0,0,0, #terminal state "tts"
                    0,0,0,0,1,0,
                    0,0,0,1,0,0,
                    0,0,0,0,1,0,
                    0,0,0,0,0,1
                    
                 
                 
                 
                 ),6, 6, byrow=TRUE)



R<- array(0, c(6,6,2))
R[,,1] <- matrix(c(
                    0,1,-1,0,0,0,
                    0,0,0,0,0,0, #terminal state "tts"
                    0,0,0,0,10,0,
                    0,0,0,0,0,0,
                    0,0,0,0,0,0,
                    0,0,0,0,0,0
                    
                 
                 
                 
                 ), 6, 6, byrow=TRUE)

R[,,2] <- matrix(c(
                    0,1,-1,0,0,0,
                    0,0,0,0,0,0, #terminal state "tts"
                    0,0,0,0,10,0,
                    0,0,0,0,0,0,
                    0,0,0,0,0,0,
                    0,0,0,0,0,0
                    
                 
                 
                 
                 ), 6, 6, byrow=TRUE)


Pol=mdp_policy_iteration_modified(P, R,discount= 0.99 )
Val=mdp_value_iteration(P,R,0.99)

Pol
Val

```
```{r}
#solve with Q learning

Q=mdp_Q_learning(P,R,discount=0.99,N=1000000)

Q$policy
Q$V

```


```{r}
#second larger MDP with probabilistic transitions
library(MDPtoolbox)
library(matlab)



P <- array(0, c(16,16,2))
P[,,1] <- matrix(c(
                   0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #terminal state "transitions to self"
                   0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
                   
                   ), 16, 16, byrow=TRUE)
P[,,2] <- matrix(c(
                   0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #terminal state "transitions to self"
                   0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.05,0.95,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
                   
                   ), 16, 16, byrow=TRUE)


R<- array(0, c(16,16,2))
R[,,1] <- matrix(c(
                   0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #terminal state "transitions to self"
                   0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,10,10000,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
                   
                   ), 16, 16, byrow=TRUE)


R[,,2] <- matrix(c(
                   0,10,-20,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, #terminal state "transitions to self"
                   0,0,0,10,-20,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,10,-20,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,10,-20,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,10,-20,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,10,-20,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,10,10000,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
                   
                   ), 16, 16, byrow=TRUE)


Pol=mdp_policy_iteration_modified(P, R,discount= 0.99 )
Val=mdp_value_iteration(P,R,0.99)

Pol
Val


```
```{r}
# Q learning with larger MDP

Q=mdp_Q_learning(P,R,discount=0.99,N=90000000)
Q$policy

```

